{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "37db3b7a-c81d-4f6a-b8a8-9f5674c6feb5",
    "deepnote_cell_type": "text-cell-h1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# RATING Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4c574a17-beaa-467a-80e8-64c8c9578cbc",
    "deepnote_cell_type": "text-cell-p",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "Comic Mischief Detection Task\n",
    "\n",
    "Files:\n",
    "\n",
    "1. \"train.csv\" : \n",
    "-- Contains multiclass classification content annotations for each video scene used in the training set.\n",
    "-- Annotations are on a scene level and do not correspond to a specific modality\n",
    "-- a \".csv\" file containing video URLs as well as the IDs of the scenes used in the training set.\n",
    "-- Videos are available in the form of URLs, collected from the Youtube and the IMDB websites.\n",
    "-- Contains metadata about the videos.\n",
    "-- Four content categories related to comic mischief are used (Sarcasm, Slapstick Humor, Gory Humor, Mature Humor).\n",
    "\n",
    "2. \"val.csv\" : \n",
    "-- Contains multiclass classification content annotations for each video scene used in the validation set.\n",
    "-- You can use this set for performing model hyperparameter tuning before using the test set\n",
    "\n",
    "\n",
    "3. \"test.csv\" : \n",
    "-- Contains multiclass classification content annotations for each video scene used in the test set.\n",
    "-- You can use this set for evaluating your method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "ae028c11-f4b1-4180-9f60-74f25891fb1f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3894,
    "execution_start": 1644814279553,
    "source_hash": "94243ef8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15600480329359836270\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6302793728\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10846578387087117228\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n",
      "2.6.0\n",
      "Num GPUs Available:  1\n",
      "device name: /device:GPU:0\n",
      "WARNING:tensorflow:From C:\\Users\\maitr\\AppData\\Local\\Temp\\ipykernel_9236\\588012342.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.__version__)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print(\"device name:\", device_name)\n",
    "\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_gpu_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "09480eaa-48a0-439d-b679-23024487d866",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1644814284695,
    "source_hash": "2000a060",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "train_dir = os.getcwd() + \"/train_data/\"\n",
    "val_dir = os.getcwd() + \"/val_data/\"\n",
    "test_dir = os.getcwd() + \"/test_data/\"\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_SEQ_LENGTH = 1440\n",
    "NUM_FEATURES = 1024\n",
    "IMG_SIZE = 224\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fdb0968c-cba8-478b-852c-4389220f825c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### References\n",
    "1. https://keras.io/examples/vision/video_transformers/)\n",
    "2. https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub)\n",
    "3. https://colab.research.google.com/github/sayakpaul/Action-Recognition-in-TensorFlow/blob/main/Data_Preparation_UCF101.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c5c164a6-1b18-4f27-a32a-1fef09258dbb",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Data Preparation (not complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "be3d8688-9ac5-4e29-9e99-f13b154a58ac",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### METADATA loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "63c68a51-5839-4d9b-9d51-4890d0bed7e1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 119,
    "execution_start": 1644814288992,
    "source_hash": "68973930",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Scene_ID</th>\n",
       "      <th>Video URL</th>\n",
       "      <th>Codec</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Avg Frame rate</th>\n",
       "      <th>Mature Humor - Scene Annotation</th>\n",
       "      <th>Slapstick Humor - Scene Annotation</th>\n",
       "      <th>Gory Humor - Scene Annotation</th>\n",
       "      <th>Sarcasm - Scene Annotation</th>\n",
       "      <th>combination</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt2872718</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.imdb.com/videoplayer/vi4179799833</td>\n",
       "      <td>h264</td>\n",
       "      <td>854 x 480</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt2872718</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.imdb.com/videoplayer/vi4179799833</td>\n",
       "      <td>h264</td>\n",
       "      <td>854 x 480</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0010</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt2788710</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.imdb.com/videoplayer/vi1114222361</td>\n",
       "      <td>h264</td>\n",
       "      <td>854 x 480</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt2788710</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.imdb.com/videoplayer/vi1114222361</td>\n",
       "      <td>h264</td>\n",
       "      <td>854 x 480</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt2788710</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.imdb.com/videoplayer/vi1114222361</td>\n",
       "      <td>h264</td>\n",
       "      <td>854 x 480</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Video ID  Scene_ID                                       Video URL Codec  \\\n",
       "0  tt2872718         0   https://www.imdb.com/videoplayer/vi4179799833  h264   \n",
       "1  tt2872718         1   https://www.imdb.com/videoplayer/vi4179799833  h264   \n",
       "2  tt2788710         0   https://www.imdb.com/videoplayer/vi1114222361  h264   \n",
       "3  tt2788710         1   https://www.imdb.com/videoplayer/vi1114222361  h264   \n",
       "4  tt2788710         2   https://www.imdb.com/videoplayer/vi1114222361  h264   \n",
       "\n",
       "  Resolution  Avg Frame rate  Mature Humor - Scene Annotation  \\\n",
       "0  854 x 480       23.976024                                0   \n",
       "1  854 x 480       23.976024                                0   \n",
       "2  854 x 480       23.976024                                0   \n",
       "3  854 x 480       23.976024                                1   \n",
       "4  854 x 480       23.976024                                0   \n",
       "\n",
       "   Slapstick Humor - Scene Annotation  Gory Humor - Scene Annotation  \\\n",
       "0                                   0                              0   \n",
       "1                                   0                              1   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "\n",
       "   Sarcasm - Scene Annotation combination  \\\n",
       "0                           0        0000   \n",
       "1                           0        0010   \n",
       "2                           0        0000   \n",
       "3                           0        1000   \n",
       "4                           0        0000   \n",
       "\n",
       "                                                path  \n",
       "0  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "1  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "2  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "3  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "4  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe which contains multiclass classification content annotations for each video scene used in the training set.\n",
    "train_df = pd.read_csv('train-updated.csv', dtype={'combination': object}).iloc[:,1:]\n",
    "train_df[\"path\"] = train_dir + train_df[\"Video ID\"]+ \".0\" + train_df[\"Scene_ID\"].astype(str) + \".mp4\"\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "f080ba32-7528-4f94-98aa-0fd621590003",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 70,
    "execution_start": 1644814290089,
    "source_hash": "b3c9ae0a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Scene_ID</th>\n",
       "      <th>Video URL</th>\n",
       "      <th>Codec</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Avg Frame rate</th>\n",
       "      <th>Mature Humor - Scene Annotation</th>\n",
       "      <th>Slapstick Humor - Scene Annotation</th>\n",
       "      <th>Gory Humor - Scene Annotation</th>\n",
       "      <th>Sarcasm - Scene Annotation</th>\n",
       "      <th>combination</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt1308728</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=QP9qbhTeBII</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.975945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1308728</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/watch?v=QP9qbhTeBII</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.975945</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1308728</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.youtube.com/watch?v=QP9qbhTeBII</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.975945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PGuqnE35cCg</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=PGuqnE35cCg</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PGuqnE35cCg</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/watch?v=PGuqnE35cCg</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID  Scene_ID                                     Video URL Codec  \\\n",
       "0    tt1308728         0   https://www.youtube.com/watch?v=QP9qbhTeBII  h264   \n",
       "1    tt1308728         1   https://www.youtube.com/watch?v=QP9qbhTeBII  h264   \n",
       "2    tt1308728         2   https://www.youtube.com/watch?v=QP9qbhTeBII  h264   \n",
       "3  PGuqnE35cCg         0   https://www.youtube.com/watch?v=PGuqnE35cCg  h264   \n",
       "4  PGuqnE35cCg         1   https://www.youtube.com/watch?v=PGuqnE35cCg  h264   \n",
       "\n",
       "  Resolution  Avg Frame rate  Mature Humor - Scene Annotation  \\\n",
       "0  640 x 360       23.975945                                1   \n",
       "1  640 x 360       23.975945                                1   \n",
       "2  640 x 360       23.975945                                1   \n",
       "3  640 x 360       23.976024                                1   \n",
       "4  640 x 360       23.976024                                1   \n",
       "\n",
       "   Slapstick Humor - Scene Annotation  Gory Humor - Scene Annotation  \\\n",
       "0                                   0                              0   \n",
       "1                                   1                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "\n",
       "   Sarcasm - Scene Annotation combination  \\\n",
       "0                           0        1000   \n",
       "1                           0        1100   \n",
       "2                           0        1000   \n",
       "3                           0        1000   \n",
       "4                           0        1000   \n",
       "\n",
       "                                                path  \n",
       "0  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "1  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "2  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "3  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "4  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe which contains multiclass classification content annotations for each video scene used in the validation set.\n",
    "val_df = pd.read_csv('val.csv', dtype={'combination': object}).iloc[:,1:]\n",
    "val_df[\"path\"] = val_dir + val_df[\"Video ID\"]+ \".0\" + val_df[\"Scene_ID\"].astype(str) + \".mp4\"\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "e2e0a169-b660-4bc0-b85d-e226eb0efde2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81,
    "execution_start": 1644814291719,
    "source_hash": "8b166588",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Scene_ID</th>\n",
       "      <th>Video URL</th>\n",
       "      <th>Codec</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Avg Frame rate</th>\n",
       "      <th>Mature Humor - Scene Annotation</th>\n",
       "      <th>Slapstick Humor - Scene Annotation</th>\n",
       "      <th>Gory Humor - Scene Annotation</th>\n",
       "      <th>Sarcasm - Scene Annotation</th>\n",
       "      <th>combination</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt1741243</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.imdb.com/videoplayer/vi2169153049</td>\n",
       "      <td>h264</td>\n",
       "      <td>534 x 360</td>\n",
       "      <td>29.970000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1741243</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.imdb.com/videoplayer/vi2169153049</td>\n",
       "      <td>h264</td>\n",
       "      <td>534 x 360</td>\n",
       "      <td>29.970000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0110</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1723121</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=O7NHfAzg7Yg</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt1723121</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/watch?v=O7NHfAzg7Yg</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt1723121</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.youtube.com/watch?v=O7NHfAzg7Yg</td>\n",
       "      <td>h264</td>\n",
       "      <td>640 x 360</td>\n",
       "      <td>23.976024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Video ID  Scene_ID                                       Video URL Codec  \\\n",
       "0  tt1741243         0   https://www.imdb.com/videoplayer/vi2169153049  h264   \n",
       "1  tt1741243         1   https://www.imdb.com/videoplayer/vi2169153049  h264   \n",
       "2  tt1723121         0     https://www.youtube.com/watch?v=O7NHfAzg7Yg  h264   \n",
       "3  tt1723121         1     https://www.youtube.com/watch?v=O7NHfAzg7Yg  h264   \n",
       "4  tt1723121         2     https://www.youtube.com/watch?v=O7NHfAzg7Yg  h264   \n",
       "\n",
       "  Resolution  Avg Frame rate  Mature Humor - Scene Annotation  \\\n",
       "0  534 x 360       29.970000                                1   \n",
       "1  534 x 360       29.970000                                0   \n",
       "2  640 x 360       23.976024                                1   \n",
       "3  640 x 360       23.976024                                1   \n",
       "4  640 x 360       23.976024                                1   \n",
       "\n",
       "   Slapstick Humor - Scene Annotation  Gory Humor - Scene Annotation  \\\n",
       "0                                   0                              0   \n",
       "1                                   1                              1   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "\n",
       "   Sarcasm - Scene Annotation combination  \\\n",
       "0                           0        1000   \n",
       "1                           0        0110   \n",
       "2                           0        1000   \n",
       "3                           0        1000   \n",
       "4                           0        1000   \n",
       "\n",
       "                                                path  \n",
       "0  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "1  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "2  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "3  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  \n",
       "4  c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe which contains multiclass classification content annotations for each video scene used in the test set.\n",
    "test_df = pd.read_csv('test-updated.csv', dtype={'combination': object}).iloc[:,1:]\n",
    "test_df[\"path\"] = test_dir + test_df[\"Video ID\"]+ \".0\" + test_df[\"Scene_ID\"].astype(str) + \".mp4\"\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "14f1fcca-b038-4f54-b98e-e54e45138366",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "07f90c3b-a279-4ab5-9501-e37a9bbb0c35",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "How to feed videos to a neural network for training? <br>\n",
    "\n",
    "1. Use OpenCV VideoCapture() method to read frames from videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "81e2aa7b-587b-4e06-ab22-3f66909bb3ab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1644814294456,
    "source_hash": "f99f02",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilities to open video files using CV2\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a68d340b-5464-4ca5-bc55-45a3d43ced3c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Feature Extraction with pre-trained DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "f786b771-abbd-49f7-8277-f9797e3db451",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4579,
    "execution_start": 1644814297807,
    "source_hash": "a12163ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.DenseNet121(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.densenet.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "80c029b6-f188-42de-8373-40e907fadd59",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Label Preprocessing \n",
    "\n",
    "Multilabel classification -->  Multi-class Binarization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "21d6d133-f626-48d3-9e9c-712e5c561422",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "No Matrure, No Slapstick, No Gory, No Sarcasm - 0000 <br>\n",
    "No Matrure, No Slapstick, No Gory, Sarcasm - 0001 <br>\n",
    "No Matrure, No Slapstick, Gory, No Sarcasm - 0010 <br>\n",
    "No Matrure, No Slapstick, Gory, Sarcasm - 0011 <br>\n",
    "No Matrure, Slapstick, No Gory, No Sarcasm - 0100 <br>\n",
    "No Matrure, Slapstick, No Gory, Sarcasm - 0101 <br>\n",
    "No Matrure, Slapstick, Gory, No Sarcasm - 0110 <br>\n",
    "No Matrure, Slapstick, Gory, Sarcasm - 0111 <br>\n",
    "Matrure, No Slapstick, No Gory, No Sarcasm - 1000 <br>\n",
    "Matrure, No Slapstick, No Gory, Sarcasm - 1001 <br>\n",
    "Matrure, No Slapstick, Gory, No Sarcasm - 1010 <br>\n",
    "Matrure, No Slapstick, Gory, Sarcasm - 1011 <br>\n",
    "Matrure, Slapstick, No Gory, No Sarcasm - 1100 <br>\n",
    "Matrure, Slapstick, No Gory, Sarcasm - 1101 <br>\n",
    "Matrure, Slapstick, Gory, No Sarcasm - 1110 <br>\n",
    "Matrure, Slapstick, Gory, Sarcasm - 1111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "65203327-f60b-42f0-911d-7b460f2edebe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 136,
    "execution_start": 1644814305741,
    "source_hash": "32006f2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000', '0001', '0010', '0011', '0100', '0101', '0110', '1000', '1001', '1010', '1011', '1100', '1101']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.experimental.preprocessing.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"combination\"]), mask_token=None\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "a4d34440-9081-4284-8d0a-1bdba0082008",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1644814396696,
    "source_hash": "52154926",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"path\"].values.tolist()\n",
    "    labels = df[\"combination\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_features` are what we will feed to our sequence model.\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        print(path)\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(path)\n",
    "        \n",
    "        # Pad shorter videos.\n",
    "        if len(frames) < MAX_SEQ_LENGTH:\n",
    "            diff = MAX_SEQ_LENGTH - len(frames)\n",
    "            padding = np.zeros((diff, IMG_SIZE, IMG_SIZE, 3))\n",
    "            frames = np.concatenate((frames, padding))\n",
    "        \n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholder to store the features of the current video.\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                if np.mean(batch[j, :]) > 0.0:\n",
    "                    temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                        batch[None, j, :]\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    temp_frame_features[i, j, :] = 0.0\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "\n",
    "    return frame_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ad9086d4-2b04-4c49-a991-8b0083510ae8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 40102,
    "execution_start": 1644814397448,
    "source_hash": "4e42359f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_videos(train_df, \"train_data\")\n",
    "val_data, val_labels = prepare_all_videos(val_df, \"val_data\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test_data\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data.shape}\")\n",
    "print(f\"Train labels: {train_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "with open('train_data.npy', 'wb') as f:\n",
    "    np.save(f, train_data)\n",
    "\n",
    "with open('train_labels.npy', 'wb') as f:\n",
    "    np.save(f, train_labels)\n",
    "\n",
    "with open('val_data.npy', 'wb') as f:\n",
    "    np.save(f, val_data)\n",
    "\n",
    "with open('val_labels.npy', 'wb') as f:\n",
    "    np.save(f, val_labels)\n",
    "\n",
    "with open('test_data.npy', 'wb') as f:\n",
    "    np.save(f, test_data)\n",
    "\n",
    "with open('test_labels.npy', 'wb') as f:\n",
    "    np.save(f, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b428fb81-cd25-48f5-9742-1f7ea202064d",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Build the Transformer-based model (not completed) - BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "e36a7e79-836f-4942-a832-d53954293523",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "51248883",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embedding Layer\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        #  x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "3e2e67d3-0540-476b-b812-04d019aa8269",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "521c40ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformer encoder implemented as a Subclassed layer\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
    "        )\n",
    "\n",
    "        # self.dense_proj = keras.Sequential(\n",
    "        #     [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        # )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    sequence_length = MAX_SEQ_LENGTH\n",
    "    embed_dim = NUM_FEATURES\n",
    "    dense_dim = 4\n",
    "    num_heads = 1\n",
    "    classes = len(label_processor.get_vocabulary())\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None))\n",
    "    x = PositionalEmbedding(\n",
    "        sequence_length, embed_dim, name=\"frame_position_embedding\"\n",
    "    )(inputs)\n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "    x = layers.Dense(units=embed_dim, activation='gelu')(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(units=embed_dim, activation='tanh')(x)\n",
    "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_experiment():\n",
    "    filepath = os.getcwd() + \"/tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    with tf.device('/device:CPU:0'):\n",
    "        model = get_compiled_model()\n",
    "        history = model.fit(\n",
    "            train_data,\n",
    "            train_labels,\n",
    "            validation_data=(val_data,val_labels),\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[checkpoint],\n",
    "        )\n",
    "\n",
    "    model.load_weights(filepath)\n",
    "    _, accuracy = model.evaluate(test_data, test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ae7a96a5-1e99-4eb3-8183-430d4b85f098",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (942, 1440, 1024)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = np.load(\"train_data.npy\"), np.load(\"train_labels.npy\")\n",
    "val_data, val_labels = np.load(\"val_data.npy\"), np.load(\"val_labels.npy\")\n",
    "test_data, test_labels = np.load(\"test_data.npy\"), np.load(\"test_labels.npy\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, None, None)]      0         \n",
      "_________________________________________________________________\n",
      "frame_position_embedding (Po (None, None, 1024)        1474560   \n",
      "_________________________________________________________________\n",
      "transformer_layer (Transform (None, None, 1024)        4211716   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, None, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "layer_normalization_17 (Laye (None, None, 1024)        2048      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 13)                13325     \n",
      "=================================================================\n",
      "Total params: 7,800,849\n",
      "Trainable params: 7,800,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 264s 9s/step - loss: 2.2049 - accuracy: 0.2972 - val_loss: 2.2427 - val_accuracy: 0.3009\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.24272, saving model to c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision\\Rating\\RATING-Project\\RATING-Project/tmp\\video_classifier\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 252s 8s/step - loss: 1.8995 - accuracy: 0.3694 - val_loss: 1.9354 - val_accuracy: 0.2655\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.24272 to 1.93544, saving model to c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision\\Rating\\RATING-Project\\RATING-Project/tmp\\video_classifier\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 261s 9s/step - loss: 1.7348 - accuracy: 0.4108 - val_loss: 1.8594 - val_accuracy: 0.3363\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.93544 to 1.85937, saving model to c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision\\Rating\\RATING-Project\\RATING-Project/tmp\\video_classifier\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 264s 9s/step - loss: 1.6314 - accuracy: 0.4183 - val_loss: 1.8439 - val_accuracy: 0.3186\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.85937 to 1.84386, saving model to c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision\\Rating\\RATING-Project\\RATING-Project/tmp\\video_classifier\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 266s 9s/step - loss: 1.5625 - accuracy: 0.4671 - val_loss: 1.9873 - val_accuracy: 0.3451\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.84386\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 263s 9s/step - loss: 1.4856 - accuracy: 0.4671 - val_loss: 1.8697 - val_accuracy: 0.3982\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.84386\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 264s 9s/step - loss: 1.3359 - accuracy: 0.5297 - val_loss: 1.8567 - val_accuracy: 0.3363\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.84386\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 266s 9s/step - loss: 1.2702 - accuracy: 0.5796 - val_loss: 1.8397 - val_accuracy: 0.3805\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.84386 to 1.83971, saving model to c:\\Users\\maitr\\Desktop\\COSC6373-ComputerVision\\Rating\\RATING-Project\\RATING-Project/tmp\\video_classifier\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 264s 9s/step - loss: 1.2858 - accuracy: 0.5594 - val_loss: 2.1863 - val_accuracy: 0.3982\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.83971\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 259s 9s/step - loss: 1.2145 - accuracy: 0.5796 - val_loss: 2.0179 - val_accuracy: 0.3540\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.83971\n",
      "4/4 [==============================] - 2s 172ms/step - loss: 1.7373 - accuracy: 0.4299\n",
      "Test accuracy: 42.99%\n"
     ]
    }
   ],
   "source": [
    "trained_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    # Pad shorter videos.\n",
    "    if len(frames) < MAX_SEQ_LENGTH:\n",
    "        diff = MAX_SEQ_LENGTH - len(frames)\n",
    "        padding = np.zeros((diff, IMG_SIZE, IMG_SIZE, 3))\n",
    "        frames = np.concatenate(frames, padding)\n",
    "\n",
    "    frames = frames[None, ...]\n",
    "\n",
    "    # Extract features from the frames of the current video.\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            if np.mean(batch[j, :]) > 0.0:\n",
    "                frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "            else:\n",
    "                frame_features[i, j, :] = 0.0\n",
    "\n",
    "    return frame_features\n",
    "\n",
    "\n",
    "def predict_action(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features = prepare_single_video(frames)\n",
    "    probabilities = trained_model.predict(frame_features)[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "# This utility is for visualization.\n",
    "# Referenced from: https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "    return embed.embed_file(\"animation.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video = np.random.choice(test_df[\"path\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "test_frames = predict_action(test_video)\n",
    "to_gif(test_frames[:MAX_SEQ_LENGTH])\n",
    "\n",
    "# test_video_paths = test_df[\"path\"].values.tolist()\n",
    "# test_labels = test_df[\"combination\"].values\n",
    "# for idx, path in enumerate(test_video_paths):\n",
    "#     print(f\"Truth label: {test_labels[idx]}\")\n",
    "#     test_frames = predict_action(path)\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=7327af42-8a03-4c46-b38e-e6931aa020f3' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "05ab0b75-b65c-4d2b-b56a-635b53176e13",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
